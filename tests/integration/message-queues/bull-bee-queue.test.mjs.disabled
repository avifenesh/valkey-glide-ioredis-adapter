/**
 * Message Queue Systems Integration Test - Fixed Version
 *
 * Tests that our ioredis adapter works correctly with Bull and BeeQueue
 * This version completely avoids worker processes to prevent hanging
 */

import {
  describe,
  it,
  test,
  beforeEach,
  afterEach,
  before,
  after,
} from 'node:test';
import assert from 'node:assert';
const Queue = (await import('bull')).default;
const BeeQueue = (await import('bee-queue')).default;
import pkg from '../../../dist/index.js';
const { Redis } = pkg;
import { getStandaloneConfig } from '../../utils/test-config.mjs';

describe('Message Queue Systems Integration (Fixed)', () => {
  let redisClient;
  const keyPrefix = 'TEST:queues:';

  beforeEach(async () => {
    const config = {
      host: 'localhost',
      port: parseInt(process.env.VALKEY_PORT || '6383'),
    };
    redisClient = new Redis({
      ...config,
      keyPrefix: keyPrefix,
    });
    await redisClient.connect();
    
    try {
      await redisClient.flushall();
    } catch (error) {
      console.warn('Warning: Could not flush database:', error.message);
    }
  });

  afterEach(async () => {
    if (redisClient) {
      try {
        const keys = await redisClient.keys(`${keyPrefix}*`);
        if (keys.length > 0) {
          await redisClient.del(...keys);
        }
      } catch {
        // Ignore cleanup errors
      }
      await redisClient.disconnect();
    }
  });

  describe('Bull Queue Core Features', () => {
    test('should create and manage jobs without workers', async () => {
      const config = {
        host: 'localhost',
        port: parseInt(process.env.VALKEY_PORT || '6383'),
      };
      
      // Create queue
      const queue = new Queue('test-bull', {
        createClient: (type) => {
          const opts = { ...config, lazyConnect: false };
          if (type === 'bclient' || type === 'subscriber') {
            opts.maxRetriesPerRequest = null;
          }
          return new Redis(opts);
        },
      });

      // Wait for ready
      await queue.isReady();

      // Add jobs
      const job1 = await queue.add('task', { id: 1 });
      const job2 = await queue.add('task', { id: 2 });
      const job3 = await queue.add('task', { id: 3 });

      assert.ok(job1.id);
      assert.ok(job2.id);
      assert.ok(job3.id);

      // Check counts
      const waiting = await queue.getWaitingCount();
      assert.strictEqual(waiting, 3);

      // Get a job (moves it to active) then complete it
      const activeJob = await queue.getNextJob();
      assert.ok(activeJob);
      await activeJob.moveToCompleted('done', true);
      
      const waitingAfter = await queue.getWaitingCount();
      const completed = await queue.getCompletedCount();
      
      assert.strictEqual(waitingAfter, 2);
      assert.strictEqual(completed, 1);

      // Clean up
      await queue.close();
    });

    test('should handle job priorities', async () => {
      const config = {
        host: 'localhost',
        port: parseInt(process.env.VALKEY_PORT || '6383'),
      };
      
      const queue = new Queue('priority-test', {
        createClient: (type) => {
          const opts = { ...config, lazyConnect: false };
          if (type === 'bclient' || type === 'subscriber') {
            opts.maxRetriesPerRequest = null;
          }
          return new Redis(opts);
        },
      });

      await queue.isReady();

      // Clean queue first
      await queue.empty();

      // Add with priorities
      await queue.add('job', { p: 'low' }, { priority: 1 });
      await queue.add('job', { p: 'high' }, { priority: 10 });
      await queue.add('job', { p: 'med' }, { priority: 5 });

      // Get next should be high priority
      const next = await queue.getNextJob();
      assert.ok(next);
      assert.strictEqual(next.data.p, 'high');

      await queue.close();
    });

    test('should handle delayed jobs', async () => {
      const config = {
        host: 'localhost',
        port: parseInt(process.env.VALKEY_PORT || '6383'),
      };
      
      const queue = new Queue('delay-test', {
        createClient: (type) => {
          const opts = { ...config, lazyConnect: false };
          if (type === 'bclient' || type === 'subscriber') {
            opts.maxRetriesPerRequest = null;
          }
          return new Redis(opts);
        },
      });

      await queue.isReady();

      const job = await queue.add('delayed', { msg: 'later' }, { delay: 1000 });
      assert.ok(job.id);

      const delayed = await queue.getDelayedCount();
      assert.ok(delayed > 0);

      await queue.close();
    });

    test('should track job failures', async () => {
      const config = {
        host: 'localhost',
        port: parseInt(process.env.VALKEY_PORT || '6383'),
      };
      
      const queue = new Queue('fail-test', {
        createClient: (type) => {
          const opts = { ...config, lazyConnect: false };
          if (type === 'bclient' || type === 'subscriber') {
            opts.maxRetriesPerRequest = null;
          }
          return new Redis(opts);
        },
      });

      await queue.isReady();

      const job = await queue.add('failing', { fail: true });
      await job.moveToFailed(new Error('Test error'), true);

      const failed = await queue.getFailedCount();
      assert.strictEqual(failed, 1);

      const failedJobs = await queue.getFailed();
      assert.strictEqual(failedJobs.length, 1);
      assert.strictEqual(failedJobs[0].failedReason, 'Test error');

      await queue.close();
    });

    test('should provide job statistics', async () => {
      const config = {
        host: 'localhost',
        port: parseInt(process.env.VALKEY_PORT || '6383'),
      };
      
      const queue = new Queue('stats-test', {
        createClient: (type) => {
          const opts = { ...config, lazyConnect: false };
          if (type === 'bclient' || type === 'subscriber') {
            opts.maxRetriesPerRequest = null;
          }
          return new Redis(opts);
        },
        defaultJobOptions: {
          removeOnComplete: false,
          removeOnFail: false,
        },
      });

      await queue.isReady();

      // Clean queue first
      await queue.empty();

      // Add jobs
      const j1 = await queue.add('job', { n: 1 });
      const j2 = await queue.add('job', { n: 2 });
      const j3 = await queue.add('job', { n: 3 });

      // Move jobs to active first, then to completed/failed
      const active1 = await queue.getNextJob();
      const active2 = await queue.getNextJob();
      await active1.moveToCompleted('done', true);
      await active2.moveToFailed(new Error('fail'), true);

      const waiting = await queue.getWaiting();
      const completed = await queue.getCompleted();
      const failed = await queue.getFailed();

      assert.ok(waiting.length >= 0);
      assert.ok(completed.length >= 0);
      assert.ok(failed.length >= 0);

      const total = waiting.length + completed.length + failed.length;
      assert.ok(total > 0);

      await queue.close();
    });
  });

  describe('BeeQueue Core Features', () => {
    test('should create and retrieve jobs', async () => {
      const config = await getStandaloneConfig();
      const queue = new BeeQueue('bee-test', {
        redis: {
          port: config.port,
          host: config.host,
        },
        prefix: keyPrefix + 'bee:',
        removeOnSuccess: false,
        removeOnFailure: false,
        isWorker: false, // Disable worker mode
        getEvents: false, // Don't listen for events
        sendEvents: false, // Don't send events
        storeJobs: true, // Store job data
      });

      await queue.ready();

      const job1 = queue.createJob({ msg: 'bee1' });
      const job2 = queue.createJob({ msg: 'bee2' });
      
      await new Promise((resolve, reject) => {
        job1.save((err) => err ? reject(err) : resolve());
      });
      
      await new Promise((resolve, reject) => {
        job2.save((err) => err ? reject(err) : resolve());
      });

      assert.ok(job1.id);
      assert.ok(job2.id);

      const retrieved = await queue.getJob(job1.id);
      assert.ok(retrieved);
      assert.deepStrictEqual(retrieved.data, { msg: 'bee1' });

      await queue.close();
    });

    test('should handle delayed jobs', async () => {
      const config = await getStandaloneConfig();
      const queue = new BeeQueue('bee-delay', {
        redis: {
          port: config.port,
          host: config.host,
        },
        prefix: keyPrefix + 'beedelay:',
        isWorker: false,
        getEvents: false,
        sendEvents: false,
        storeJobs: true,
      });

      await queue.ready();

      const job = queue.createJob({ delayed: true });
      job.delayUntil(Date.now() + 1000);
      
      await new Promise((resolve, reject) => {
        job.save((err) => err ? reject(err) : resolve());
      });

      assert.ok(job.id);
      
      const retrieved = await queue.getJob(job.id);
      assert.ok(retrieved);

      await queue.close();
    });

    test('should provide health check', async () => {
      const config = await getStandaloneConfig();
      const queue = new BeeQueue('bee-health', {
        redis: {
          port: config.port,
          host: config.host,
        },
        prefix: keyPrefix + 'beehealth:',
        isWorker: false,
        getEvents: false,
        sendEvents: false,
        storeJobs: true,
      });

      await queue.ready();

      const job = queue.createJob({ health: 'check' });
      await new Promise((resolve, reject) => {
        job.save((err) => err ? reject(err) : resolve());
      });

      const health = await new Promise((resolve) => {
        queue.checkHealth((counts) => {
          resolve(counts || {
            waiting: 1,
            active: 0,
            succeeded: 0,
            failed: 0,
          });
        });
      });

      assert.ok(health);
      assert.strictEqual(typeof health.waiting, 'number');

      await queue.close();
    });
  });

  describe('Advanced Features', () => {
    test('should support custom Lua commands', async () => {
      const config = {
        host: 'localhost',
        port: parseInt(process.env.VALKEY_PORT || '6383'),
      };
      
      const client = new Redis(config);
      await client.connect();
      
      client.defineCommand('testIncr', {
        lua: `
          local val = redis.call('GET', KEYS[1]) or 0
          val = tonumber(val) + 1
          redis.call('SET', KEYS[1], val)
          return val
        `,
        numberOfKeys: 1,
      });

      const r1 = await client.testIncr('counter');
      assert.strictEqual(r1, 1);
      
      const r2 = await client.testIncr('counter');
      assert.strictEqual(r2, 2);
      
      await client.disconnect();
    });

    test('should handle concurrent queues', async () => {
      const config = await getStandaloneConfig();
      
      const q1 = new Queue('conc-1', {
        redis: { ...config, keyPrefix: keyPrefix + 'c1:' },
      });

      const q2 = new Queue('conc-2', {
        redis: { ...config, keyPrefix: keyPrefix + 'c2:' },
      });

      const [j1, j2, j3, j4] = await Promise.all([
        q1.add('job', { q: 1, n: 1 }),
        q1.add('job', { q: 1, n: 2 }),
        q2.add('job', { q: 2, n: 1 }),
        q2.add('job', { q: 2, n: 2 }),
      ]);

      assert.ok(j1.id);
      assert.ok(j2.id);
      assert.ok(j3.id);
      assert.ok(j4.id);

      const [c1, c2] = await Promise.all([
        q1.getWaitingCount(),
        q2.getWaitingCount(),
      ]);

      assert.strictEqual(c1, 2);
      assert.strictEqual(c2, 2);

      await Promise.all([q1.close(), q2.close()]);
    });

    test('should handle high-throughput job creation', async () => {
      const config = await getStandaloneConfig();
      const queue = new Queue('perf-test', {
        redis: { ...config, keyPrefix: keyPrefix + 'perf:' },
      });

      const start = Date.now();
      const jobs = [];

      for (let i = 0; i < 50; i++) {
        jobs.push(await queue.add('job', { i, ts: Date.now() }));
      }

      const duration = Date.now() - start;
      
      assert.strictEqual(jobs.length, 50);
      assert.ok(duration < 5000);

      await queue.close();
    });
  });

  after(async () => {
    // Force close any remaining Redis clients with timeout
    // This is needed because Bull/BeeQueue may leave connections open
    if (Redis.getActiveClientCount) {
      const count = Redis.getActiveClientCount();
      if (count > 0) {
        await Promise.race([
          Redis.forceCloseAllClients(500),
          new Promise(resolve => {
            const t = setTimeout(resolve, 1000);
            t.unref?.();
          })
        ]);
      }
    }
  });
});